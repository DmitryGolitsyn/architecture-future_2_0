@startuml C4_Container_Diagram
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml

title Container Diagram - "Будущее 2.0" Architecture (Future State)

Person(doctors, "Врачи", "Медицинский персонал")
Person(finance, "Финансисты", "Финансовые специалисты") 
Person(analysts, "Аналитики", "Бизнес-аналитики")
Person(admins, "Админы", "Системные администраторы")

System_Boundary(portal_boundary, "Data Portal System") {
    Container(data_portal, "Data Portal", "React/Vue SPA", "Self-service BI портал с конструктором отчетов")
}

System_Boundary(gateway_boundary, "API Gateway Layer") {
    Container(api_gateway, "API Gateway", "Kong/Envoy", "Маршрутизация, аутентификация, rate limiting")
}

System_Boundary(domains_boundary, "Domain Services") {
    Container(medical_domain, "Medical Domain", "Python/FastAPI", "Управление пациентами, медкарты, AI диагностика")
    Container(fintech_domain, "FinTech Domain", "Go/Java Spring", "Банковские услуги, платежи, кредиты")
    Container(analytics_domain, "Analytics Domain", "Python/FastAPI", "Отчеты, метрики, KPI, ML модели")
    Container(equipment_domain, "Equipment Domain", "Java Spring", "Инвентаризация, поставки, обслуживание")
}

System_Boundary(streaming_boundary, "Event Streaming") {
    Container(kafka_cluster, "Apache Kafka", "Event Streaming", "Доменные события, real-time синхронизация, аудит")
}

System_Boundary(processing_boundary, "Data Processing") {
    Container(stream_proc, "Stream Processing", "Kafka Streams", "Real-time агрегация и обработка событий")
    Container(batch_proc, "Batch Processing", "Spark/Airflow", "ETL процессы, качество данных, трансформации")
    Container(ml_pipeline, "ML Pipeline", "MLflow/Kubeflow", "Обучение моделей, A/B тестирование, serving")
}

System_Boundary(storage_boundary, "Data Storage") {
    ContainerDb(analytical_db, "Analytical DB", "ClickHouse/Snowflake", "OLAP, витрины данных, отчетность")
    ContainerDb(operational_db, "Operational DBs", "PostgreSQL/MongoDB", "OLTP, транзакционные данные")
    ContainerDb(search_engine, "Search Engine", "Elasticsearch", "Полнотекстовый поиск, логирование")
    ContainerDb(cache, "Cache", "Redis", "Кеширование сессий и запросов")
}

System_Boundary(legacy_boundary, "Legacy Integration") {
    ContainerDb(legacy_dwh, "Legacy DWH", "SQL Server 2008", "Старое хранилище данных (read-only)")
}

' User interactions
Rel(doctors, data_portal, "Просматривает медицинские отчеты")
Rel(finance, data_portal, "Создает финансовые отчеты")
Rel(analysts, data_portal, "Конструирует аналитические отчеты")
Rel(admins, data_portal, "Администрирует систему")

' Portal to Gateway
Rel(data_portal, api_gateway, "API запросы", "HTTPS/REST")

' Gateway to Domains
Rel(api_gateway, medical_domain, "Медицинские данные", "HTTP/REST")
Rel(api_gateway, fintech_domain, "Финансовые данные", "HTTP/REST")  
Rel(api_gateway, analytics_domain, "Аналитические данные", "HTTP/REST")
Rel(api_gateway, equipment_domain, "Данные оборудования", "HTTP/REST")

' Domains to Streaming
Rel(medical_domain, kafka_cluster, "Медицинские события", "Kafka")
Rel(fintech_domain, kafka_cluster, "Финансовые события", "Kafka")
Rel(analytics_domain, kafka_cluster, "Аналитические события", "Kafka")
Rel(equipment_domain, kafka_cluster, "События оборудования", "Kafka")

' Streaming to Processing
Rel(kafka_cluster, stream_proc, "Потоковая обработка", "Kafka Streams")
Rel(kafka_cluster, batch_proc, "Пакетная обработка", "Kafka Connect")
Rel(kafka_cluster, ml_pipeline, "ML события", "Kafka")

' Processing to Storage
Rel(stream_proc, analytical_db, "Агрегированные данные", "SQL")
Rel(batch_proc, analytical_db, "ETL результаты", "SQL")
Rel(ml_pipeline, analytical_db, "ML метрики", "SQL")

Rel(medical_domain, operational_db, "Операционные данные", "SQL")
Rel(fintech_domain, operational_db, "Транзакции", "SQL")
Rel(analytics_domain, search_engine, "Поисковые индексы", "HTTP")
Rel(data_portal, cache, "Кеширование", "Redis Protocol")

' Legacy Integration
Rel(batch_proc, legacy_dwh, "CDC миграция", "SQL")
Rel_Back(legacy_dwh, analytical_db, "Миграция данных", "ETL")

SHOW_LEGEND()
@enduml 